#+title:  Hypothesis Testing
#+author: Daniel Ballesteros-Ch√°vez
#+language: en
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 26.1 (Org mode 9.3.6)
#+PROPERTY: header-args :R+ :exports both
#+PROPERTY: header-args :R+ :session *R*
#+HTML_HEAD: <style type="text/css"> tr:nth-child(odd) {background-color: #e2e2e2;}  tr:first-child {font-weight: bold}  tr:hover {background-color: #d0c6e5;}</style>
#+HTML_HEAD_EXTRA: <style>code {background-color: #ccc}</style>
:results:
#+HTML_HEAD:<style>
#+HTML_HEAD:/* Daniel Ballesteros-Chavez */
#+HTML_HEAD:/* DBCh CSS for blog project */
#+HTML_HEAD:/* color schemes: #333745; #E63462 ; #C7EFCF ; #EEF5DB ; #909396; #262626;*/
#+HTML_HEAD:/* Modified version with responsive TOC
#+HTML_HEAD:
#+HTML_HEAD:/* usage: #+HTML_HEAD: <link rel="stylesheet" type="text/css" href="./style01.css"/> */
#+HTML_HEAD:
#+HTML_HEAD:body {
#+HTML_HEAD:	font-size: 18px;
#+HTML_HEAD:	color: #404040;
#+HTML_HEAD:	/* background-color: #333745; */
#+HTML_HEAD:	font-family: Helvetica;
#+HTML_HEAD:	line-height: 1.3;
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:#content {
#+HTML_HEAD:	max-width: 50em;
#+HTML_HEAD:	margin-left: auto;
#+HTML_HEAD:	margin-right: auto;
#+HTML_HEAD:    padding: 15px 50px 50px 15px;
#+HTML_HEAD:    background-color: #E4F7FF;
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:p {
#+HTML_HEAD:		text-align: justify;
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:
#+HTML_HEAD:/* this part is about the table of contents TOC */
#+HTML_HEAD:
#+HTML_HEAD:#table-of-contents a:link,
#+HTML_HEAD:#table-of-contents a:visited {
#+HTML_HEAD:    color: #404040;
#+HTML_HEAD:    background: transparent;
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:#table-of-contents a:hover {
#+HTML_HEAD:  background-color: #ccc;
#+HTML_HEAD:  color: #404040;
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:
#+HTML_HEAD:#table-of-contents {
#+HTML_HEAD:    line-height: 1.2;
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:#table-of-contents h2 {
#+HTML_HEAD:    background-color:  #ccc ;
#+HTML_HEAD:    padding-left: 0.3em;
#+HTML_HEAD:    color: #404040;
#+HTML_HEAD:    border-bottom: 0;
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:#table-of-contents ul {
#+HTML_HEAD:    list-style: none;
#+HTML_HEAD:    padding-left: 0.3em;
#+HTML_HEAD:    font-weight: normal;
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:
#+HTML_HEAD:#table-of-contents div>ul>li {
#+HTML_HEAD:    margin-top: 1em;
#+HTML_HEAD:    font-weight: bold;
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:#table-of-contents .tag {
#+HTML_HEAD:    display: none;
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:#table-of-contents .todo,
#+HTML_HEAD:#table-of-contents .done {
#+HTML_HEAD:    font-size: 80%;
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:#table-of-contents ol>li {
#+HTML_HEAD:    margin-top: 1em;
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:@media screen {
#+HTML_HEAD:
#+HTML_HEAD:    #table-of-contents {
#+HTML_HEAD:        position: fixed;
#+HTML_HEAD:        top: 0;
#+HTML_HEAD:        left: 0;
#+HTML_HEAD:        padding: 1em 0 1em 1em;
#+HTML_HEAD:        width: 290px;
#+HTML_HEAD:        height: 100vh;
#+HTML_HEAD:        overlow-x: hidden;
#+HTML_HEAD:        overlow-y: auto;
#+HTML_HEAD:	overflow: auto;
#+HTML_HEAD:    }
#+HTML_HEAD:
#+HTML_HEAD:    #table-of-contents h2 {
#+HTML_HEAD:        margin-top: 0;
#+HTML_HEAD:        font-family: Helvetica,Arial,"Lucida Grande",sans-serif;
#+HTML_HEAD:    }
#+HTML_HEAD:
#+HTML_HEAD:    #table-of-contents code {
#+HTML_HEAD:        font-size: 12px;
#+HTML_HEAD:    }
#+HTML_HEAD:    
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:@media screen and (max-width: 95em) {
#+HTML_HEAD:
#+HTML_HEAD:    #table-of-contents {
#+HTML_HEAD:        display: none;
#+HTML_HEAD:    }
#+HTML_HEAD:
#+HTML_HEAD:    h1.title {
#+HTML_HEAD:        margin-left: 0%;
#+HTML_HEAD:    }
#+HTML_HEAD:    
#+HTML_HEAD:    div#content {
#+HTML_HEAD:        margin-left: 5%;
#+HTML_HEAD:        max-width: 90%;
#+HTML_HEAD:    }
#+HTML_HEAD:}
#+HTML_HEAD:
#+HTML_HEAD:/*Html Boxes around THMs and Propositions */
#+HTML_HEAD:.abstract  {
#+HTML_HEAD:    	color:  #404040;
#+HTML_HEAD:	border: 1px solid #404040;
#+HTML_HEAD:    box-shadow: 3px 3px 3px ;
#+HTML_HEAD:    padding: 8pt;
#+HTML_HEAD:    overflow: auto;
#+HTML_HEAD:    margin: 1.2em;
#+HTML_HEAD:    position: relative;
#+HTML_HEAD:    overflow: auto;
#+HTML_HEAD:    padding-top: 1.2em;
#+HTML_HEAD:	   }
#+HTML_HEAD:
#+HTML_HEAD:  .abstract:before {
#+HTML_HEAD:    display: inline;
#+HTML_HEAD:    position: absolute;
#+HTML_HEAD:    background-color: white;
#+HTML_HEAD:    top: -5px;
#+HTML_HEAD:    left: 10px;
#+HTML_HEAD:    padding: 3px;
#+HTML_HEAD:    border: 1px solid black;
#+HTML_HEAD:    content: 'Abstract';
#+HTML_HEAD:  }
#+HTML_HEAD:
#+HTML_HEAD:.mydef  {
#+HTML_HEAD:    	color:  #404040;
#+HTML_HEAD:    border: 1px solid #404040;
#+HTML_HEAD:    background-color: #FFD580;
#+HTML_HEAD:    /* box-shadow: 3px 3px 3px orange; */
#+HTML_HEAD:    padding: 8pt;
#+HTML_HEAD:    overflow: auto;
#+HTML_HEAD:    margin: 1.2em;
#+HTML_HEAD:    position: relative;
#+HTML_HEAD:    overflow: auto;
#+HTML_HEAD:    padding-top: 1.2em;
#+HTML_HEAD:	   }
#+HTML_HEAD:
#+HTML_HEAD:  .mydef:before {
#+HTML_HEAD:    display: inline;
#+HTML_HEAD:    position: absolute;
#+HTML_HEAD:    /* background-color: white; */
#+HTML_HEAD:    background-color: orange;
#+HTML_HEAD:    top: -5px;
#+HTML_HEAD:    left: 10px;
#+HTML_HEAD:    padding: 3px;
#+HTML_HEAD:    border: 1px solid black;
#+HTML_HEAD:    content: 'Definition';
#+HTML_HEAD:  }
#+HTML_HEAD:
#+HTML_HEAD:.prop  {
#+HTML_HEAD:    	color:  #404040;
#+HTML_HEAD:    border: 1px solid ;
#+HTML_HEAD:    background-color: #F1FFC2;
#+HTML_HEAD:    /* box-shadow: 3px 3px 3px green; */
#+HTML_HEAD:    padding: 8pt;
#+HTML_HEAD:    overflow: auto;
#+HTML_HEAD:    margin: 1.2em;
#+HTML_HEAD:    position: relative;
#+HTML_HEAD:    overflow: auto;
#+HTML_HEAD:    padding-top: 1.2em;
#+HTML_HEAD:	   }
#+HTML_HEAD:
#+HTML_HEAD:  .prop:before {
#+HTML_HEAD:    	color:  white;
#+HTML_HEAD:    display: inline;
#+HTML_HEAD:    position: absolute;
#+HTML_HEAD:    background-color: green;
#+HTML_HEAD:    top: -5px;
#+HTML_HEAD:    left: 10px;
#+HTML_HEAD:    padding: 3px;
#+HTML_HEAD:    border: 1px solid black;
#+HTML_HEAD:    content: 'Proposition';
#+HTML_HEAD:  }
#+HTML_HEAD:
#+HTML_HEAD:.thm  {
#+HTML_HEAD:    	color:  #404040;
#+HTML_HEAD:    border: 1px solid ;
#+HTML_HEAD:    background-color: lightcyan;
#+HTML_HEAD:    /* box-shadow: 3px 3px 3px brown; */
#+HTML_HEAD:    padding: 8pt;
#+HTML_HEAD:    overflow: auto;
#+HTML_HEAD:    margin: 1.2em;
#+HTML_HEAD:    position: relative;
#+HTML_HEAD:    overflow: auto;
#+HTML_HEAD:    padding-top: 1.2em;
#+HTML_HEAD:	   }
#+HTML_HEAD:
#+HTML_HEAD:  .thm:before {
#+HTML_HEAD:    	color:  white;
#+HTML_HEAD:    display: inline;
#+HTML_HEAD:    position: absolute;
#+HTML_HEAD:    background-color: darkblue;
#+HTML_HEAD:    top: -5px;
#+HTML_HEAD:    left: 10px;
#+HTML_HEAD:    padding: 3px;
#+HTML_HEAD:    border: 1px solid black;
#+HTML_HEAD:    content: 'Theorem';
#+HTML_HEAD:  }
#+HTML_HEAD:
#+HTML_HEAD:  .cor  {
#+HTML_HEAD:    	color:  #404040;
#+HTML_HEAD:    border: 1px solid blue;
#+HTML_HEAD:    box-shadow: 3px 3px 3px blue;
#+HTML_HEAD:    padding: 8pt;
#+HTML_HEAD:    overflow: auto;
#+HTML_HEAD:    margin: 1.2em;
#+HTML_HEAD:    position: relative;
#+HTML_HEAD:    overflow: auto;
#+HTML_HEAD:    padding-top: 1.2em;
#+HTML_HEAD:	   }
#+HTML_HEAD:
#+HTML_HEAD:  .cor:before {
#+HTML_HEAD:    display: inline;
#+HTML_HEAD:    position: absolute;
#+HTML_HEAD:    background-color: white;
#+HTML_HEAD:    top: -5px;
#+HTML_HEAD:    left: 10px;
#+HTML_HEAD:    padding: 3px;
#+HTML_HEAD:    border: 1px solid black;
#+HTML_HEAD:    content: 'Corollary';
#+HTML_HEAD:  }
#+HTML_HEAD:
#+HTML_HEAD:
#+HTML_HEAD:
#+HTML_HEAD:/*defaults form org-mode export */
#+HTML_HEAD:
#+HTML_HEAD:
#+HTML_HEAD:  .title  { text-align: center; }
#+HTML_HEAD:  .todo   { font-family: monospace; color: red; }
#+HTML_HEAD:  .done   { color: green; }
#+HTML_HEAD:  .tag    { background-color: #eee; font-family: monospace;
#+HTML_HEAD:            padding: 2px; font-size: 80%; font-weight: normal; }
#+HTML_HEAD:  .timestamp { color: #bebebe; }
#+HTML_HEAD:  .timestamp-kwd { color: #5f9ea0; }
#+HTML_HEAD:  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
#+HTML_HEAD:  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
#+HTML_HEAD:  .center { margin-left: auto; margin-right: auto; text-align: center; }
#+HTML_HEAD:  .underline { text-decoration: underline; }
#+HTML_HEAD:  #postamble p, #preamble p { font-size: 90%; margin: .2em; text-align: center;}
#+HTML_HEAD:  p.verse { margin-left: 3%; }
#+HTML_HEAD:  pre {
#+HTML_HEAD:    border: 1px solid #ccc;
#+HTML_HEAD:    box-shadow: 3px 3px 3px #eee;
#+HTML_HEAD:    padding: 8pt;
#+HTML_HEAD:    font-family: monospace;
#+HTML_HEAD:    overflow: auto;
#+HTML_HEAD:    margin: 1.2em;
#+HTML_HEAD:  }
#+HTML_HEAD:  pre.src {
#+HTML_HEAD:    position: relative;
#+HTML_HEAD:    overflow: auto;
#+HTML_HEAD:    padding-top: 1.2em;
#+HTML_HEAD:  }
#+HTML_HEAD:  pre.src:before {
#+HTML_HEAD:    display: none;
#+HTML_HEAD:    position: absolute;
#+HTML_HEAD:    background-color: white;
#+HTML_HEAD:    top: -10px;
#+HTML_HEAD:    right: 10px;
#+HTML_HEAD:    padding: 3px;
#+HTML_HEAD:    border: 1px solid black;
#+HTML_HEAD:  }
#+HTML_HEAD:  pre.src:hover:before { display: inline;}
#+HTML_HEAD:  pre.src-sh:before    { content: 'sh'; }
#+HTML_HEAD:  pre.src-bash:before  { content: 'sh'; }
#+HTML_HEAD:  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
#+HTML_HEAD:  pre.src-R:before     { content: 'R'; }
#+HTML_HEAD:  pre.src-perl:before  { content: 'Perl'; }
#+HTML_HEAD:  pre.src-java:before  { content: 'Java'; }
#+HTML_HEAD:  pre.src-sql:before   { content: 'SQL'; }
#+HTML_HEAD:
#+HTML_HEAD:  table { border-collapse:collapse; }
#+HTML_HEAD:  caption.t-above { caption-side: top; }
#+HTML_HEAD:  caption.t-bottom { caption-side: bottom; }
#+HTML_HEAD:  td, th { vertical-align:top;  }
#+HTML_HEAD:  th.right  { text-align: center;  }
#+HTML_HEAD:  th.left   { text-align: center;   }
#+HTML_HEAD:  th.center { text-align: center; }
#+HTML_HEAD:  td.right  { text-align: right;  }
#+HTML_HEAD:  td.left   { text-align: left;   }
#+HTML_HEAD:  td.center { text-align: center; }
#+HTML_HEAD:  dt { font-weight: bold; }
#+HTML_HEAD:  .footpara:nth-child(2) { display: inline; }
#+HTML_HEAD:  .footpara { display: block; }
#+HTML_HEAD:  .footdef  { margin-bottom: 1em; }
#+HTML_HEAD:  .figure { padding: 1em; }
#+HTML_HEAD:  .figure p { text-align: center; }
#+HTML_HEAD:  .inlinetask {
#+HTML_HEAD:    padding: 10px;
#+HTML_HEAD:    border: 2px solid gray;
#+HTML_HEAD:    margin: 10px;
#+HTML_HEAD:    background: #ffffcc;
#+HTML_HEAD:  }
#+HTML_HEAD:  #org-div-home-and-up
#+HTML_HEAD:   { text-align: right; font-size: 70%; white-space: nowrap; }
#+HTML_HEAD:  textarea { overflow-x: auto; }
#+HTML_HEAD:  .linenr { font-size: smaller }
#+HTML_HEAD:  .code-highlighted { background-color: #ffff00; }
#+HTML_HEAD:  .org-info-js_info-navigation { border-style: none; }
#+HTML_HEAD:  #org-info-js_console-label
#+HTML_HEAD:    { font-size: 10px; font-weight: bold; white-space: nowrap; }
#+HTML_HEAD:  .org-info-js_search-highlight
#+HTML_HEAD:    { background-color: #ffff00; color: #000000; font-weight: bold; }
#+HTML_HEAD:
#+HTML_HEAD:</style>
:end:


* Introduction

The goal of hypothesis testing is to assess the evidence provided by the data in favour of some claim
about the population parameters. 


The hypothesis is a statement about a population parameter.
The first step of hypothesis testing is to formulate hypothesis statements - the null hypothesis and
alternative hypothesis.


* Hypothesis

*The null hypothesis*, denoted $H_0$ , is a statement of no effect or no difference. When performing
the hypothesis test, we assess the strength of evidence against the null hypothesis.

*The alternative hypothesis*, denoted $H_1$ is the statement that we suspect is true instead of $H_0$ . If
there is evidence against $H_0$ , then we may conclude that there is evidence for H_1 as the statement
explaining our parameter. $H_1$ is usually a statement of a difference.


A *one-sided* or one-tailed test ‚Äì the population parameter differs from its hypothesised value in
a specific direction, that is the parameter is either larger or smaller than the hypothesised value.


A *two-sided* or two-tailed test ‚Äì the population parameter is different from the hypothesised
value; the direction is not specified.

* Example

Formulate the null and alternative hypotheses for the following research question: Is the
average monthly rent of a one-bedroom flat in Gliwice more than PLN 600?


Denote the mean monthly rent of all one-bedroom flats in Gliwice by $\mu$. We are comparing $\mu$ to
the value of PLN 600, and we are interested whether $\mu$ is larger than PLN 600, so it is an one-sided test.
Our hypotheses are:
\begin{equation}
H_0 : \mu = 600 , \qquad H_1 : \mu > 600
\end{equation}


* Test statistic

The test statistic is a random variable with a known distribution and will depend on the type of
statistical test we are carrying out.


In practice, we collect the data and we calculate the value of test statistic for the specific data sample,
using a formula.

* Z-test

The test statistic for one of the most common tests, Z-test, is given by
\begin{equation}
Z = \frac{\hat{\theta} - \mu_0}{\sigma/\sqrt{n}},
\end{equation}

where $\mu_0$ is the value of the hypothesised population mean. We have already proven that
$Z \sim N(0,1)$.

Note: The test statistic is based on the statistic that estimates the parameter that appears in the hypotheses.
E.g. in the example above $\hat{\theta}$ estimates $\mu_0$.

*Remark* Usually the estimator of the mean $\hat{\theta}$ is given by the arithmetic average $\hat{Y}$ (see next section).

* Some remarks with the previous formula:
 Recall that
1) If $X_{i}$ 's are $n$ iid random variables with $X_{i}\sim N(\mu, \sigma^2)$ then
\begin{equation}
\hat{Y} = \frac{1}{n} \sum_{i=1}^n X_{i} \sim N\left(\mu,\frac{\sigma^2}{n} \right).
\end{equation}

2) [@2] Then the Z statistic is the change of variable that transforms $\hat{Y} \sim N\left(\mu_0,\frac{\sigma^2}{n} \right)$ into $Z \sim N(0,1)$.

* Assessing our estimate

To assess how far the estimate is from the parameter, we standardise the estimate. So, the test
statistics are commonly in the form
\begin{equation}
\frac{\sigma_{\hat{\theta}}}{\hat{\theta}}
\end{equation}

For example: the *coefficient of variation* (CV) is the ratio of the standard
deviation to the mean and shows the extent of variability in relation
to the mean of the population. The higher the CV, the greater the
dispersion.

* p- Value

The test statistic is used for the probability calculation which indicates the strength of evidence
against $H_0$ , so called p-value.


Definition of p-value: The p-value of a test is the probability, assuming $H_0$ is true, that we
would obtain a value of our test statistic as extreme result or even more extreme than the one we have observed.

Extreme here means /far from what we expect/, assuming $H_0$ is true. 
The direction counting as /far from what we expect/ is determined by $H_1$ .

The smaller the p-value we get, the stronger the evidence against $H_0$ we have, given by
our data.

In many disciplines, the p-value is then compared to the significance level of the test.
The significance level, denoted by $\alpha$, can be thought of as an evidence threshold.


* General rules (for all hypothesis tests):

+ If the p-value is less or equal to this threshold, that is $p \leq \alpha$,
  then we reject the null hypothesis $H_0$ at $\alpha$ and there is
  evidence to support the alternative hypothesis $H_1$ , based on our
  data.
+ If $p > \alpha$, then we fail to reject $H_0$ at $\alpha$ and there
  is not enough evidence to support $H_1$ , based on our data.

* Summary

+ State the null and alternative hypotheses.
+ Calculate the value of the test statistic. (This will usually  be the Z statistic.)
+ Find a p-value for the test.
+ Decide whether to reject or not to reject the null hypothesis at the significance level $\alpha$.


* Remarks


When we reject $H_0$, it does not mean that it is not true, it just means that based on our data, we
found evidence against $H_0$ and so, in turn, we have evidence to support $H_1$.


Similarly, if we fail to reject $H_0$ , it does not make $H_0$ necessarily true, it just means that based on
our data, we do not have enough evidence against $H_0$.


When interpreting results practically, we usually do so with respect to the alternative hypothesis.


* Example

Cholesterol level in a particular population was known to have a mean value $\mu = 170$
in the past. We also know that the population standard deviation of the cholesterol is $\sigma = 30$.
A random sample of $n = 20$ people was taken and their sample mean was $185$. 

Perform a Z-test to determine whether there is evidence that the population mean has increased. Test at the 5%
significance level.

** Solution

Since $p = 0.01255 < 0.05$, we reject $H_0$ at the 5% level. We can conclude that there is evidence that
the mean cholesterol level has increased from $170$.

* Strength of the evidence

Even though in many disciplines, the significance level $\alpha$ is decided in advance, we do not really need
to have a priori this value. We can just look at the p-value and see how big it is. Then based on the
following rules, we can determine the strength of evidence against $H_0$ and so in turn, the strength of
evidence to support $H_1$ :

+ If $p > 0.10$, there is very little evidence against $H_0$ or we can say there is no evidence against $H_0$ .
+ If $0.05 < p \leq 0.10$, there is weak evidence against $H_0$ .
+ If $0.01 < p \leq 0.05$, there is evidence against $H_0$ .
+ If $0.001 < p \leq 0.01$, there is strong evidence against $H_0$ .
+ If $p \leq 0.001$, there is very strong evidence against $H_0$ .


* Using critical values for hypothesis testing

There are methods which can be used to decide whether we can reject or not to
reject they null hypothesis $H_0$ at some $\alpha$ without finding the exact p-value. A traditional method of hypothesis testing
uses a table of known critical values.

We reject the null hypothesis $H_0$ at the significance level Œ±, depending on $H_1$ , following these
rules (for most parametric tests):

+ If $H_1$ : parameter < hypothesised value, then we reject $H_0$ at $\alpha$, if
  the value of the test statistic is less than (or equal to) the
  critical value at $\alpha$ for the lower tail of the relevant distribution.
+ If $H_1$ : parameter > hypothesised value, then we reject $H_0$ at $\alpha$, if
  the value of the test statistic is greater than (or equal to) the
  critical value at Œ± for the upper tail of the relevant distribution.
+ If $H_1$ : parameter $\neq$ hypothesised value, then we reject $H_0$ at $\alpha$,
  if the value of the test statistic is less than (or equal to) the
  critical value at $\alpha/2$ for the lower tail of the relevant
  distribution or greater than (or equal to) the critical value at $\alpha/2$
  for the upper tail of the relevant distribution.

* Error Types

Remember that we make an inference about population parameters, using a particular sample, and
we do not know the population parameters. We usually do not know whether our inference is correct
or not. In reaching a decision, we may make two types of errors:

+ Type I error: We reject $H_0$ when $H_0$ is in fact true
+ Type II error: We fail to reject $H_0$ when $H_0$ is in fact false.

* Example

A new low cost diagnostic test has been developed that claims to diagnose a particular
medical condition in its early stages. The patient is assumed not to have the condition unless there
is evidence from the test to contradict this. We will discuss Type I and Type II errors in this context
and their consequences. First, we formulate the hypotheses:
+ $H_0$ : The patient does not have the condition.
+ $H_1$ : The patient has the condition.


A Type I error is when the condition is diagnosed in a patient that does not have the condition.
This would result in an expensive treatment being administered, as well as any possible side effects
of such treatment. Note that a Type I error is sometimes referred to as a false positive.


A Type II error is when the condition is not diagnosed in a patient that has the condition. This
could result in the condition progressing and possibly going unnoticed. Note that a Type II error is
sometimes referred to as a false negative.


* t-Test (Student's Distribution)

The underlying assumption for these tests is that the population is normally distributed.
There are two types of tests for a population mean, depending on whether the population variance
$\sigma^2$  is known or not.

+ If $\sigma^2$ is known, then we use the Z-test.
+ If $\sigma^2$ is unknown, then we use the t-test (with $n-1$ degrees of freedom).

The corresponding formula is given by
\begin{equation}
t = \frac{\hat{\theta} - \mu_0}{S/\sqrt{n}},
\end{equation}
where $S^2$ is the population variance.

*Remark* Usually the estimator of the mean $\hat{\theta}$ is given by the arithmetic average $\hat{Y} = \frac{1}{n}\sum_{i+1}^n X_{i}$.


* Z-test

+ State hypotheses, the null hypothesis $H_0 : \mu = \mu_0$ and the
  alternative hypothesis $H_1 : \mu < \mu_0$ for the lower tail,
  $H_1 : \mu > \mu_0$ for the upper tail, or $H_1 : \mu = \mu_0$ for
  the two-tailed alternative.

+ Calculate the test statistic
\begin{equation}
Z = \frac{\hat{\theta}-\mu_0}{\sigma/\sqrt{n}}.
\end{equation}

+ Compare the value of the test statistic to the critical value in the
  standard normal distribution tables for the relevant significance
  level, remembering to half the significance level for a two- tailed
  test. Alternatively, compute the p-value.


+ Decide whether to reject or not to reject the null hypothesis at $\alpha$. Remember that $Z \sim N (0, 1)$ and so we use critical values $z_{\alpha}$ or $z_{Œ±/2}$ as following
  + For the alternative $H_1 : \mu < \mu_0$ , we reject $H_0$ at $\alpha$ if $Z < ‚àíz_{\alpha}$.
  + For the alternative $H_1 : \mu > \mu_0$ , we reject $H_0$ at $\alpha$ if $Z > z_{\alpha}$.
  + For the alternative $H_1 : \mu \neq \mu_0$ , we reject $H_0$ at $\alpha$ if $|Z| > z_{\alpha/2}$.
  + If we calculate the exact p-value, then, of course, we use general rules: That is if $p \leq \alpha$, then we reject $H_0$ at $\alpha$, otherwise we fail to reject $H_0$ at $\alpha$.

+ Interpret your conclusion practically in the context of the question.


* Example

Cholesterol level in a particular population was known to have a mean value $\mu = 170$
in the past. We also know that the population standard deviation of the cholesterol is $\sigma = 30$.
A random sample of $n = 20$ people was taken and their sample mean was $185$. Perform Z-test
to determine whether there is evidence that the population mean has increased. Test at the 5%
significance level. You may assume that the cholesterol level is normally distributed.

Note that we solved this problem before, but this time we solve it without calculating the exact
p-value; we use critical values.

In the tables we look for the critical value at the 5% level, that is z(0.05) = 1.6449. We compare
this with the value of test statistic 2.236. Since $2.236 > 1.6449$, we reject $H_0$ at the 5% level. Note
that since our alternative is $H_1 : \mu > 170$, we used the rejection rule for $H_1 : \mu > \mu_0$ , which is that
we reject $H_0$ at $\alpha$ if $Z > z_{\alpha}$.

There is evidence that mean cholesterol level has increased from $170$.

* Exercise

Perform Z-test to
determine whether there is evidence that the population mean differs from 170. You may assume
that the cholesterol level is normally distributed.


* More graphical example

+ Usually have a sample $X_1, X_2, \ldots, X_n$, of size $n$. 
+ We want to perform an hypothesis test for the population mean. 
+ The estimate for the population mean will be denoted by $\hat{\theta}$ or $\hat{\mu}$,
+ The sample variance will be denoted by $\hat{S}^2$.
+ If the Central Limit Theorem applies, we use the $Z-test$, otherwise we use the $t-test$ with $n-1$ degrees of freedom.

** TODO Insert a graph.

** One-sided Hypothesis test
With an $\alpha$ level of confidence, perform the hypothesis test:
\begin{equation}
\begin{split}
H_0 : \mu = \mu_0,\\
H_1 : \mu > \mu_0,
\end{split}
\end{equation}


+ If we draw the Normal Distribution with $N(\mu_0, \hat{S}/ \sqrt{n})$, and identify our estimate for the mean $\hat{\theta}$:

#+latex: \includegraphics[width = 7cm]{HT_s1.pdf}

+ The formula : $Z = (\hat{\theta} - \mu_0)/(S/\sqrt{n})$, transforms
  the previous drawing into an equivalent one for the Standard Normal
  Distribution $N(0,1)$.

#+latex: \includegraphics[width = 7cm]{HT_s2.pdf}

+ The p-value is the shaded area under the curve (in this case) to the left of $Z$ as shown below

#+latex: \includegraphics[width = 7cm]{HT_s3.pdf}


+ When we are given the $\alpha$ level (usually 5%), we use it to find
  the rejection area. An area equals to the $\alpha$ value,
  corresponds a $z_{\alpha}$ score

#+latex: \includegraphics[width = 7cm]{HT_s4.pdf}

+ Then, the following comparisons are related:
  + A comparison between the p-value with the $\alpha$ level (comparing areas).
  + A comparison between the statistic $Z$ and the $z_{\alpha}$ (comparing scores).


#+ATTR_LATEX: :environment longtable :align |l|l|l|
|-------------------+---------------------+-----------------------|
| $Z$ vs $z_\alpha$ | p-value vs $\alpha$ | Conclusion            |
|-------------------+---------------------+-----------------------|
| Z > $z_{\alpha}$  | p-value < $\alpha$  | we reject $H_0$       |
|-------------------+---------------------+-----------------------|
| Z < $z_{\alpha}$  | p-value > $\alpha$  | we can't reject $H_0$ |
|-------------------+---------------------+-----------------------|


* Comparing two means

We will work out the probability that two samples were indeed
drawn from populations with the same mean. If this probability is very
low (say, less than 5% or less than 1%) then we can be reasonably
certain (95% or 99% in these two examples) than the means really are
different from one another. Note, however, that we can never be 100%
certain; the apparent difference might just be due to random sampling.

There are two classical tests for comparing two sample means: 

+ Student‚Äôs t test when the samples are independent, the variances constant, and the errors are normally distributed; 
+ Wilcoxon‚Äôs rank-sum test when the samples are independent but the errors are not normally distributed (e.g. they are ranks or scores or some sort).  


What to do when these assumptions are violated (e.g. when the variances are different) is discussed later on.

* t-Student test
The test statistic is the number of standard errors of the difference by which the two sample means are separated
\begin{equation}
t = \frac{\hat{Y}_1 - \hat{Y}_2}{ s_{\mbox{diff}}},
\end{equation}

Where
\begin{equation}
s_{\mbox{diff}} = \sqrt{\frac{s^2_{1}}{n_1} + \frac{s^2_{2}}{n_2}}
\end{equation}

In R we use the function
#+begin_example R
t.test(Sample_A, Sample_B)
#+end_example

* Binomial test to compare two proportions

Suppose that only four females were promoted, compared to 196 men. Is this an example of blatant sexism,
as it might appear at Ô¨Årst glance? Before we can judge, of course, we need to know the number of male
and female candidates. It turns out that 196 men were promoted out of 3270 candidates, compared with 4
promotions out of only 40 candidates for the women. Now, if anything, it looks like the females did better
than males in the promotion round (10% success for women versus 6% success for men).
The question then arises as to whether the apparent positive discrimination in favour of women is statisti-
cally signiÔ¨Åcant, or whether this sort of difference could arise through chance alone. 

In R the binomial proportions test is performed by the function  ~prop.test~ in which we specify two vectors, the Ô¨Årst containing the
number of successes for females and males c(4,196) and second containing the total number of female
and male candidates c(40,3270)


#+begin_src R :results output :exports both
prop.test(c(4,196), c(40,3270))
#+end_src

#+RESULTS:
#+begin_example

	2-sample test for equality of proportions with continuity correction

data:  c(4, 196) out of c(40, 3270)
X-squared = 0.52289, df = 1, p-value = 0.4696
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.06591631  0.14603864
sample estimates:
    prop 1     prop 2 
0.10000000 0.05993884 

Warning message:
In prop.test(c(4, 196), c(40, 3270)) :
  Chi-squared approximation may be incorrect
#+end_example


* Summary

In hypothesis testing, there are certain steps one must follow. Below these are summarized into six such steps to conducting a test of a hypothesis.

1. The *null hypothesis*, notated as, which is a statement of a particular parameter value. This hypothesis is assumed to be true until there is evidence to suggest otherwise. 

2. The *alternative hypothesis* is a statement of a range of alternative values in which the parameter may fall. 

3. One must also check that any conditions (assumptions) needed to run the test have been satisfied e.g. *normality of data*, *independence*, and number of success and failure outcomes.

4. *Decide on the significance level*. This alpha value represents the
   probability we are willing to place on our test for making an
   incorrect decision in regards to rejecting the null hypothesis. The
   most common value is 0.05 or 5%. Other popular choices are 0.01
   (1%) and 0.1 (10%).

5) *Calculate the test statistic*. The test statistic is calculated under the
   assumption the null hypothesis is true and incorporates a measure
   of standard error and assumptions (conditions) related to the
   sampling distribution. Here we have used the Z-statistic and the t-statistic.

6) Calculate probability value (*p-value*), or the rejection region: A
   p-value is found by using the test statistic to calculate the
   probability of the sample data producing such a test statistic or
   one more extreme. The rejection region is found by using alpha to
   find a critical value; the rejection region is the area that is
   more extreme than the critical value.

7)  *Make a decision about the null hypothesis*: In this step, we decide
   to either *reject the null hypothesis* or decide to *fail to reject*
   *the null hypothesis*. Notice we do not make a decision where we will
   accept the null hypothesis.

8) *State an overall conclusion*: Once we have found the p-value or
   rejection region, and made a statistical decision about the null
   hypothesis (i.e. we will reject the null or fail to reject the
   null), we then want to summarise our results into an overall
   conclusion for our test.

* Code for the graphs
:PROPERTIES:
:BEAMER_OPT: shrink=50
:END:

#+begin_example R
my_plot1 <- function(x,y,color="#3498db",ylabel="f(x)",xlabel="x",my.title="Plot title",...){
par(family="mono",fg="grey10") 
plot(x,y,
main=my.title,
ylab = ylabel,
xlab = xlabel,
col= color,
type= "l",
lwd="3",...
)
abline(v=x,col="grey80",lty=3)
abline(h=seq(min(y),max(y),length.out=length(x)),col="grey80",lty=3)
abline(v=0,h=0,col="grey10")
}

## I have the previous code in my_Rtools.R and just call
## suorce("./my_Rtools.R")

png("Image_name.png")  ## look aslo at pdf(), jpeg() and other file types. (?png)
XX  <-  seq (-5,5, by= 0.05)
YY  <- dnorm(XX)
my_plot1(XX,YY ,my.title="Hypothesis Test Example", xlabel = " ", xaxt="n", yaxt = "n")
axis(1,labels=FALSE)
abline(v=0, lty=3, col="red", lwd = 3)
axis(1,0,"0",lwd = 3, col = "red")
abline(v=1.8, lty=3, col="orange", lwd = 3)
axis(1,1.8, expression(paste("Z",alpha)),lwd = 3, col = "orange")
polygon(
    c( XX[XX>= 1.8], 1.8),
    c(YY[XX>= 1.8], YY[XX==5]),
    col="yellow")
text(2.03,0.025, expression(alpha))
dev.off()
#+end_example





* References

[1] Slides based on Lecture Notes on "Statistical Theory and Methods 1" at Liverpool University.

[2] Data Analysis Using Regression And Multilevel/Hierarchical Models. Andrew Gelman and Jennifer Hill. Cambridge University Press. 2007.

[3] The R book. Michael J. Crawley. John Wiley & Sons, Ltd. 2013.

[4] https://online.stat.psu.edu/stat500/lesson/6a/6a.2
